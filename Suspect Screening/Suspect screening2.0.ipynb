{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1b222c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#MS data pre-analysis by MS-DIAL 5.3. Only peak table as txt. format was needed.\n",
    "#This script is specifically designed for carbon–carbon (C–C) backbone oligomers in water sample MS data.\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "peak_table = pd.read_table('WW.txt')\n",
    "bk_table = pd.read_table('GCKB.txt')\n",
    "output_path = 'WW_output.xlsx'  \n",
    "Mode = \"negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eee2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Peaktable clean########\n",
    "clean1 = 1\n",
    "clean2 = 1\n",
    "\n",
    "if clean1 == 1:\n",
    "    # Ensure 'Isotope' column is treated as string\n",
    "    peak_table['Isotope'] = peak_table['Isotope'].astype(str)\n",
    "\n",
    "    # Filter rows where 'Isotope' is \"0\" or \"1\"\n",
    "    peak_table = peak_table[peak_table['Isotope'].isin([\"0\", \"1\"])]\n",
    "\n",
    "    # Reset index to keep the DataFrame tidy\n",
    "    peak_table.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Define thresholds\n",
    "    sn_threshold = 3          # Signal-to-noise (S/N) ratio threshold\n",
    "    area_threshold = 10000    # Area threshold\n",
    "    mz_threshold = 0.005      # m/z threshold for grouping\n",
    "    rt_threshold = 0.2        # RT (Retention Time) threshold for grouping\n",
    "\n",
    "    # Filter based on S/N and Area thresholds\n",
    "    peak_table = peak_table.query('`S/N` >= @sn_threshold and `Area` >= @area_threshold')\n",
    "\n",
    "    # Sort by 'Precursor m/z' for consistent grouping\n",
    "    peak_table = peak_table.sort_values('Precursor m/z')\n",
    "\n",
    "    # Initialize an empty list to store grouped rows\n",
    "    groups = []\n",
    "\n",
    "    # Group peaks based on m/z and RT thresholds, keeping the one with the maximum Area\n",
    "    while not peak_table.empty:\n",
    "        # Identify the group based on thresholds\n",
    "        group_mask = (peak_table['Precursor m/z'].sub(peak_table.iloc[0]['Precursor m/z']).abs() <= mz_threshold) & \\\n",
    "                     (peak_table['RT (min)'].sub(peak_table.iloc[0]['RT (min)']).abs() <= rt_threshold)\n",
    "        group = peak_table[group_mask]\n",
    "\n",
    "        # Keep the row with the maximum Area within the group\n",
    "        largest_area_row = group.loc[group['Area'].idxmax()]\n",
    "        groups.append(largest_area_row)\n",
    "\n",
    "        # Remove grouped rows from the DataFrame\n",
    "        peak_table = peak_table[~group_mask]\n",
    "\n",
    "    # Create the final DataFrame from grouped rows\n",
    "    peak_table = pd.DataFrame(groups)\n",
    "\n",
    "if clean2 == 1:    \n",
    "    # Parameters for blank deduction\n",
    "    proportion = 0.3  # Signal intensity proportion cutoff\n",
    "    # Initialize an empty set to store indices of rows to remove\n",
    "    to_remove = set()\n",
    "\n",
    "    # Iterate over each row in the peak table\n",
    "    for i, peak_row in peak_table.iterrows():\n",
    "        for _, bk_row in bk_table.iterrows():\n",
    "            # Calculate m/z difference\n",
    "            mz_difference = abs(peak_row['Precursor m/z'] - bk_row['Precursor m/z'])\n",
    "            if mz_difference <= mz_threshold:\n",
    "                # Calculate RT difference\n",
    "                rt_difference = abs(peak_row['RT (min)'] - bk_row['RT (min)'])\n",
    "                if rt_difference <= rt_threshold:\n",
    "                    # Calculate intensity proportion\n",
    "                    proportion_cal = peak_row['Area'] / bk_row['Area']\n",
    "                    if proportion_cal <= proportion:\n",
    "                        to_remove.add(i)\n",
    "                        break  # Stop checking further blanks for this peak\n",
    "\n",
    "    # Remove rows marked for removal\n",
    "    peak_table = peak_table.drop(index=list(to_remove)).reset_index(drop=True)\n",
    "\n",
    "# Display the cleaned peak_table\n",
    "\n",
    "peak_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45f885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Exact mass calculation#########\n",
    "columns_to_drop = [\n",
    "    'Sharpness', 'Gaussian similarity', 'Ideal slope', 'Symmetry', 'Model masses', \n",
    "     'Isotope', 'Comment', 'Reference RT', 'Reference m/z', 'Formula', \n",
    "    'Ontology', 'InChIKey', 'SMILES', 'Annotation tag (VS1.0)', 'RT matched', \n",
    "    'm/z matched', 'MS/MS matched', 'RT similarity', 'm/z similarity', \n",
    "    'Simple dot product', 'Weighted dot product', 'Reverse dot product', \n",
    "    'Matched peaks count', 'Matched peaks percentage', 'Total score', 'S/N'\n",
    "]\n",
    "\n",
    "peak_table = peak_table .drop(columns=columns_to_drop)\n",
    "\n",
    "\n",
    "def Get_Adduct_Mass(Mode, Adduct):\n",
    "    Z = 0\n",
    "    \n",
    "    if Mode == \"negative\":\n",
    "        if Adduct == \"[M-H]-\":\n",
    "            Z = -1.0072766\n",
    "        elif Adduct == \"[M+H2O-H]-\":\n",
    "            Z = 17.0032881\n",
    "        elif Adduct == \"[M+Cl]-\":\n",
    "            Z = 33.9615761\n",
    "        elif Adduct == \"[M+FA-H]-\":\n",
    "            Z = 44.9982027\n",
    "        elif Adduct == \"[M+Hac-H]-\":\n",
    "            Z = 59.0138527\n",
    "        elif Adduct == \"[M-2H]2-\":\n",
    "            Z = -2.0145532\n",
    "    \n",
    "    if Mode == \"positive\":\n",
    "        if Adduct == \"[M+H]+\":\n",
    "            Z = 1.0072767\n",
    "        elif Adduct == \"[M+Na]+\":\n",
    "            Z = 22.9892213\n",
    "        elif Adduct == \"[M+K]+\":\n",
    "            Z = 38.9631585\n",
    "        elif Adduct == \"[M+H-H2O]+\":\n",
    "            Z = -17.0021912\n",
    "        elif Adduct == \"[M+ACN+H]+\":\n",
    "            Z = 42.0338258\n",
    "        elif Adduct == \"[M+CH3OH+H]+\":\n",
    "            Z = 33.0334914\n",
    "        elif Adduct == \"[M+NH4]+\":\n",
    "            Z = 19.0416508\n",
    "        elif Adduct == \"[M+2H]2+\":\n",
    "            Z = 2.0145533\n",
    "    \n",
    "    return Z\n",
    "\n",
    "peak_table['Mass'] = 0.0\n",
    "\n",
    "for index, row in peak_table.iterrows():\n",
    "    try:\n",
    "        Adduct = row['Adduct']\n",
    "        \n",
    "        # 提取电荷\n",
    "        match = re.search(r\".*\\](.)\", Adduct)\n",
    "        if match:\n",
    "            Charge = match.group(1)\n",
    "        else:\n",
    "            print(f\"Adduct format invalid at index {index}: {Adduct}\")\n",
    "            continue\n",
    "        \n",
    "        if Charge == \"+\" or Charge == \"-\":\n",
    "            Charge = 1.0\n",
    "        else:\n",
    "            Charge = float(Charge)\n",
    "\n",
    "        Precursor = row['Precursor m/z']\n",
    "        Z = Get_Adduct_Mass(Mode, Adduct)\n",
    "\n",
    "        Mass = Precursor * Charge - Z\n",
    "        peak_table.at[index, 'Mass'] = Mass\n",
    "    except Exception as e:\n",
    "        print(f\"Error at index {index}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cec7f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "########Oligomer finder by suspect screening###########\n",
    "\n",
    "ppm = 1e-6  # Global variable.\n",
    "\n",
    "peak_table['DP'] = 0\n",
    "peak_table['EG'] = None\n",
    "peak_table['RU'] = None\n",
    "\n",
    "Olig_df = pd.read_excel('Plastic oligomer suspect list.xlsx')\n",
    "\n",
    "for index, row1 in peak_table.iterrows():\n",
    "    for _, row2 in Olig_df.iterrows():\n",
    "\n",
    "        n_estimate = round((row1['Mass'] - row2['Differ mass']) / row2['NL mass'])\n",
    "        if n_estimate <= 0:  \n",
    "            continue\n",
    "        \n",
    "        # Check the upper and lower ranges of the estimates (e.g. ±2 range)\n",
    "        for n in range(n_estimate - 3, n_estimate + 3):\n",
    "            if n <= 0:  \n",
    "                continue\n",
    "\n",
    "            calculated_mass = row1['Mass'] - row2['NL mass'] * n - row2['Differ mass']\n",
    "            if abs(calculated_mass) < 10 * ppm * row1['Mass']:  \n",
    "                peak_table.at[index, 'DP'] = n\n",
    "                peak_table.at[index, 'RU'] = row2['Acronyms']\n",
    "                peak_table.at[index, 'EG'] = row2['Differ formula']\n",
    "                break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa0aa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "########Diagnostic NL check#############\n",
    "\n",
    "minint = 0.01\n",
    "mass_tolerance_NL = 0.005  # Da\n",
    "\n",
    "# 初始化 peak_table\n",
    "peak_table['MS2feature'] = 'NaN'  \n",
    "peak_table.reset_index(drop=True, inplace=True)\n",
    "\n",
    "for i in range(len(peak_table)):\n",
    "    # for di-carboxylic end structure\n",
    "    if peak_table[\"EG\"][i] == \"C2H2O4\":  \n",
    "        nl = 43.9898292\n",
    "        precursor = float(peak_table[\"Precursor m/z\"][i])\n",
    "\n",
    "        ms2peak_table = str(peak_table[\"MSMS spectrum\"][i]).split(\";\")\n",
    "        if ms2peak_table != ['nan']:\n",
    "            peak_table.at[i, 'MS2feature'] = 'N'\n",
    "            ms2peak_table = pd.DataFrame(\n",
    "                [x.split(\" \") for x in ms2peak_table],\n",
    "                columns=[\"mz\", \"intensity\"]\n",
    "            )\n",
    "            ms2peak_table['mz'] = pd.to_numeric(ms2peak_table['mz'])\n",
    "            ms2peak_table['intensity'] = pd.to_numeric(ms2peak_table['intensity'])\n",
    "            ms2peak_table[\"Rintensity\"] = ms2peak_table['intensity'] / max(ms2peak_table['intensity'])\n",
    "\n",
    "            ms2peak_table = ms2peak_table[ms2peak_table['mz'] <= precursor + mass_tolerance_NL]\n",
    "\n",
    "            matched_row_index = None\n",
    "\n",
    "            for j in range(len(ms2peak_table)):\n",
    "                if (\n",
    "                    abs(precursor - ms2peak_table[\"mz\"].iloc[j] - nl) < mass_tolerance_NL and\n",
    "                    ms2peak_table[\"Rintensity\"].iloc[j] >= minint\n",
    "                ):\n",
    "                    matched_row_index = j\n",
    "                    break\n",
    "\n",
    "            # If a matching row is found, mark NL as 'Y'\n",
    "            if matched_row_index is not None:\n",
    "                peak_table.at[i, 'NL'] = 'Y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7eb2666",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### RT prediction #############\n",
    "peak_table['PredictedRT'] = 'NaN'  \n",
    "\n",
    "peak_table['Row_Index'] = peak_table.index  \n",
    "grouped = peak_table.groupby(['RU', 'EG'])['Row_Index'].apply(list).reset_index()\n",
    "\n",
    "grouped.rename(columns={'Row_Index': 'Row_Indices'}, inplace=True)\n",
    "# Iterate over each group\n",
    "for i in range(len(grouped)):\n",
    "    # Get the row indices for the current group\n",
    "    group_indices = grouped.at[i, 'Row_Indices']\n",
    "    \n",
    "    # Extract DP and RT (min) values for the current group\n",
    "    dp_values = peak_table.loc[group_indices, 'DP']\n",
    "    rt_values = peak_table.loc[group_indices, 'RT (min)']\n",
    "    \n",
    "    # Find the minimum dp value where dp > 3\n",
    "    dp_min = dp_values[dp_values > 3].min() if (dp_values > 3).any() else None\n",
    "\n",
    "# Find the largest RT value corresponding to dp_min\n",
    "    if dp_min is not None:\n",
    "        rt_min = rt_values[dp_values == dp_min].max()  # Selects the largest RT for dp_min\n",
    "    else:\n",
    "        rt_min = None\n",
    "\n",
    "    # Find the maximum dp value where dp <= 12\n",
    "    dp_max = dp_values[dp_values <= 12].max() if (dp_values <= 12).any() else None\n",
    "\n",
    "# Find the largest RT value corresponding to dp_max\n",
    "    if dp_max is not None:\n",
    "        rt_max = rt_values[dp_values == dp_max].max()\n",
    "    else:\n",
    "        rt_max = None\n",
    "    \n",
    "    # Check if dp_min and dp_max are valid and not equal\n",
    "    if dp_min is not None and dp_max is not None and dp_min != dp_max:\n",
    "        # Fit the equation RT = k * ln(DP) + b\n",
    "        k = (rt_max - rt_min) / (np.log(dp_max) - np.log(dp_min))\n",
    "        b = rt_min - k * np.log(dp_min)\n",
    "        \n",
    "        # Update PredictedRT for each peak in the group\n",
    "        for j in group_indices:\n",
    "            dp = peak_table.at[j, 'DP']\n",
    "            if dp > 1:  # Ensure DP is greater than 1 for log computation\n",
    "                predicted_rt = k * np.log(dp) + b\n",
    "                peak_table.at[j, 'PredictedRT (min)'] = round(predicted_rt, 3)\n",
    "    else:\n",
    "        # If dp_min and dp_max are equal or invalid, use rt_min directly\n",
    "        for j in group_indices:\n",
    "            peak_table.at[j, 'PredictedRT'] = rt_min if rt_min is not None else np.nan\n",
    "columns_to_drop = ['RT left (min)', 'RT right (min)', 'Estimated noise', \n",
    "                   'S/N.1', 'MS1 isotopes', 'MSMS spectrum', 'Row_Index']\n",
    "\n",
    "# Drop the specified columns from peak_table\n",
    "peak_table.drop(columns=columns_to_drop, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214c60ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_table.to_excel(output_path, index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-scz",
   "language": "python",
   "name": "py311-scz"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
